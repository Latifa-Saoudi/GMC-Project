import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn import metrics
from sklearn.preprocessing import StandardScaler

data1=pd.read_csv('/content/KO_1919-09-06_2025-04-17.csv')
data1

# Conversion de la date
data1["date"] = pd.to_datetime(data1["date"])
data1.sort_values("date", inplace=True)

# Création de la variable cible (valeur de 'close' du jour suivant)
data1["close_tomorrow"] = data1["close"].shift(-1)

data1

# 1. Range de la journée : high - low
data1["daily_range"] = data1["high"] - data1["low"]

# 2. Variation intraday : close - open
data1["intraday_change"] = data1["close"] - data1["open"]

# 3. Volume relatif à la moyenne mobile (sur 10 jours ici, mais tu peux ajuster)
data1["avg_volume_10"] = data1["volume"].mean()
data1["volume_rel"] = data1["volume"] / data1["avg_volume_10"]

data1

data1.isnull().sum()

data1.dropna(inplace=True)

data1.isnull().sum()

Nom de la feature	Description
daily_range	:Amplitude journalière des prix

intraday_change	:Évolution intra-journalière

volume_rel	:Indique si le volume est élevé/faible vs. moyen

# **Visualization**

data1['daily_return'] = data1['adj_close'].pct_change()
data1['daily_return'].hist(bins=50)

data1['rolling_mean_30'] = data1['adj_close'].rolling(window=30).mean()
data1[['adj_close', 'rolling_mean_30']].plot()

# Set plot style
sns.set(style="whitegrid", palette="muted")
plt.figure(figsize=(14, 6))

# 1. Line plot of closing price
plt.subplot(2, 2, 1)
plt.plot(data1['date'], data1['close'], label='Close', linewidth=1)
plt.title("Stock Closing Price Over Time")
plt.xlabel("Date")
plt.ylabel("Close Price")
plt.legend()

# 2. Daily Range over time
plt.subplot(2, 2, 2)
plt.plot(data1['date'], data1['daily_range'], color='orange', linewidth=1)
plt.title("Daily Price Range Over Time")
plt.xlabel("Date")
plt.ylabel("High - Low")

# 3. Intraday Change Distribution
plt.subplot(2, 2, 3)
sns.histplot(data1['intraday_change'], bins=50, kde=True, color='green')
plt.title("Distribution of Intraday Change (Close - Open)")

# 4. Relative Volume over time
plt.subplot(2, 2, 4)
plt.plot(data1['date'], data1['volume_rel'], color='purple', linewidth=1)
plt.axhline(y=1, color='gray', linestyle='--')
plt.title("Relative Volume Over Time")
plt.xlabel("Date")
plt.ylabel("Volume / Avg Volume (10 days)")

plt.tight_layout()
plt.show()

# Stock Closing Price Over Time:

Shows long-term growth and major market events (e.g., 2000 dot-com bubble, 2008 crisis, 2020 COVID crash).

# Daily Price Range Over Time:

Highlights volatility spikes — possibly during crises or earnings announcements.

# Intraday Change Distribution:

Almost normal distribution, but with slight skew and fat tails — useful for modeling price movement.

# Relative Volume Over Time:

Very insightful for spotting high-activity periods (volume spikes > average).

plt.figure(figsize=(10, 6))
corr = data1[['open', 'high', 'low', 'close', 'adj_close', 'close_tomorrow',
           'daily_range', 'intraday_change', 'volume', 'avg_volume_10', 'volume_rel']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

data1.drop(["intraday_change","avg_volume_10"], axis=1, inplace=True)

data1['ma30'] = data1['close'].rolling(window=30).mean()
data1['ma90'] = data1['close'].rolling(window=90).mean()
data1[['date', 'close', 'ma30', 'ma90']].set_index('date').plot(figsize=(12, 5))
plt.title("Close vs. Moving Averages")
plt.show()

from pickle import TRUE
data1['date'] = pd.to_datetime(data1['date'],utc=True)

# Now you can use the .dt accessor
data1['decade'] = data1['date'].dt.year // 10 * 10
sns.boxplot(x='decade', y='volume', data=data1)
plt.title("Trading Volume by Decade")
plt.show()

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV # Import GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge, Lasso # Import Ridge and Lasso
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score

# Définir X et y
features = ['open', 'high', 'low', 'close', 'adj_close', 'volume',
            'daily_range', 'volume_rel']
X = data1[features]
y = data1["close_tomorrow"]

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)

# Modèle
models = {
    "Linear": LinearRegression(),
    "Ridge": Ridge(),
    "Lasso": Lasso(),
    "RandomForest": RandomForestRegressor(),
    "XGBoost": xgb.XGBRegressor()  # optional
}

# --- Parameter grids for search ---
param_grids = {
    "Ridge": {'alpha': [0.1, 1.0, 10.0]},
    "Lasso": {'alpha': [0.001, 0.01, 0.1]},
    "RandomForest": {'n_estimators': [100, 200], 'max_depth': [5, 10, None]},
    "XGBoost": {'n_estimators': [100, 200], 'max_depth': [3, 6]}
}

# --- Training and tuning ---
results = {}

for name, model in models.items():
    print(f"Training: {name}")
    
    if name in param_grids:
        grid = GridSearchCV(model, param_grids[name], cv=3, scoring='neg_root_mean_squared_error')
        grid.fit(X_train, y_train)
        best_model = grid.best_estimator_
        print(f"Best params for {name}: {grid.best_params_}")
    else:
        best_model = model.fit(X_train, y_train)
    
    y_pred = best_model.predict(X_test)
    
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    results[name] = {"rmse": rmse, "r2": r2}

# --- Show Results ---
print("\nModel Evaluation:")
for name, score in results.items():
    print(f"{name} -> RMSE: {score['rmse']:.4f}, R²: {score['r2']:.4f}")

import joblib
model=models['Linear']
joblib.dump(model, 'linear_model.pkl')

joblib.load('linear_model.pkl')

d=pd.read_pickle('linear_model.pkl')
d

